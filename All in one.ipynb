{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45373607",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d1fae",
   "metadata": {},
   "source": [
    "I will try (and fail probably) to put everything into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f3154",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from qwikidata.sparql  import return_sparql_query_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import urllib.request\n",
    "import json\n",
    "import string\n",
    "from difflib import SequenceMatcher\n",
    "from viapy.api import ViafAPI\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fae3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_save = \"data/final_files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ade72",
   "metadata": {},
   "source": [
    "# 1. Download all WikiData entries\n",
    "Goal: To download (using SparQL queries) all WikiData entries that have VIAF ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80789b5c",
   "metadata": {},
   "source": [
    "A. Get all WikiData entries with VIAF ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af61a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"\n",
    "        SELECT DISTINCT ?item ?viaf # return QID and VIAF ID\n",
    "WHERE \n",
    "{ ?item wdt:P214 ?viaf. # select all the items in WikiData that have VIAF ID\n",
    "\n",
    "}\n",
    "        \"\"\"\n",
    "start = time.time()\n",
    "items_with_viaf = return_sparql_query_results(query_string) # run the query and get results\n",
    "print(\"It took \"+str(np.round(time.time()-start,2))+ \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b43e6",
   "metadata": {},
   "source": [
    "B. Process results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_viaf = pd.DataFrame(items_with_viaf[\"results\"][\"bindings\"])\n",
    "items_with_viaf[\"item\"] = items_with_viaf[\"item\"].apply(lambda x: x[\"value\"].split(\"/\")[-1]) # keep only QID\n",
    "items_with_viaf[\"viaf\"] = items_with_viaf[\"viaf\"].apply(lambda x: x[\"value\"]) # keep only VIAF ID\n",
    "items_with_viaf.columns = [\"QID\", \"viaf_id\"] # rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e00b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_viaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In WikiData, there are \"+str(len(items_with_viaf))+\" items with VIAF ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddbf5a",
   "metadata": {},
   "source": [
    "C. Save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save with Pickle\n",
    "# with open(location_to_save + \"items_with_viaf_wikidata.pkl\", \"wb\") as output_file:\n",
    "#     pkl.dump(items_with_viaf, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2ab3a",
   "metadata": {},
   "source": [
    "# 2. Recreate Fairbook dataset\n",
    "Goal: To cut down the dataset the same way that they did in FairBook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaded2b",
   "metadata": {},
   "source": [
    "A. Read files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1fb9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/ratings_books.csv\", low_memory=False).fillna(\"\")\n",
    "dataset.columns = ['User-ID', 'ISBN', 'Book-Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5a3ea",
   "metadata": {},
   "source": [
    "B. Print statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "693c576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset statistics: \n",
      "> No. of users: 105283\n",
      "> No. of Books: 340556\n",
      "> No. of Interaction: 1149780\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset statistics: \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56cb7d",
   "metadata": {},
   "source": [
    "C. Filter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d58ba0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rows_by_values(df, col, values):\n",
    "    return df[~df[col].isin(values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4af1b9",
   "metadata": {},
   "source": [
    "C.1. Remove implicit (i.e. 0) ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c2ba106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit dataset statistics: \n",
      "> No. of users: 77805\n",
      "> No. of Books: 185973\n",
      "> No. of Interaction: 433671\n"
     ]
    }
   ],
   "source": [
    "dataset = filter_rows_by_values(dataset, \"Book-Rating\", [0])\n",
    "\n",
    "# statistics on explicit dataset\n",
    "print(\"Explicit dataset statistics: \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cee96",
   "metadata": {},
   "source": [
    "C.2. Remove:\n",
    "1. Users with more than 200 ratings\n",
    "2. Users with less than 5 rarings\n",
    "3. Items with less than 5 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d450b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users with more than 200 interactions: 144\n"
     ]
    }
   ],
   "source": [
    "# To check if there is any user with more than 200 interaction in the preprocessed dataset\n",
    "# The correct output will be zero\n",
    "uid_value_counts = dataset['User-ID'].value_counts()\n",
    "print(\"The number of users with more than 200 interactions:\", len(uid_value_counts[uid_value_counts > 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b58c689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the users with fewer than 5 interaction we first count the number of interactino per user and add a new column (`Count`) in the dataframe.\n",
    "# This column shows the number of interaction per user in the dataset\n",
    "users_counts = dataset['User-ID'].value_counts()\n",
    "users_counts = users_counts.to_dict() #converts to dictionary\n",
    "dataset['Count'] = dataset['User-ID'].map(users_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33e3642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filter_rows_by_values(dataset, \"Count\", list(range(200, max(dataset['Count']) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5496bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset statistics (users with interactions < 200): \n",
      "> No. of users: 77660\n",
      "> No. of Books: 156891\n",
      "> No. of Interaction: 364245\n"
     ]
    }
   ],
   "source": [
    "# statistics on explicit dataset after removing users with more than 200 int.\n",
    "print(f\"New dataset statistics (users with interactions < {200}): \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c5dbe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 63585\n",
      "No. of items < 5 ineractions: 119254\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 5825\n",
      "No. of items < 5 ineractions: 1594\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 432\n",
      "No. of items < 5 ineractions: 208\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 69\n",
      "No. of items < 5 ineractions: 45\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 19\n",
      "No. of items < 5 ineractions: 17\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 11\n",
      "No. of items < 5 ineractions: 13\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 6\n",
      "No. of items < 5 ineractions: 2\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 2\n",
      "No. of items < 5 ineractions: 4\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 1\n",
      "No. of items < 5 ineractions: 1\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 0\n",
      "No. of items < 5 ineractions: 0\n"
     ]
    }
   ],
   "source": [
    "user_interaction, item_interaction = 1, 1\n",
    "\n",
    "while user_interaction != 0 or item_interaction != 0:\n",
    "    print(f\"The current number of user and item with < 5 interactions: \")\n",
    "    # user side fewer than ds_rate cheking\n",
    "    uid_value_counts = dataset['User-ID'].value_counts()\n",
    "    user_interaction = uid_value_counts[uid_value_counts < 5].count()\n",
    "    print(f\"No. of users < 5 ineractions: {user_interaction}\")\n",
    "\n",
    "    users_counts = dataset['User-ID'].value_counts()\n",
    "    users_counts = users_counts.to_dict() #converts to dictionary\n",
    "    dataset['Count'] = dataset['User-ID'].map(users_counts)\n",
    "\n",
    "    dataset = filter_rows_by_values(dataset, \"Count\", list(range(5)))\n",
    "\n",
    "    # item side fewer than ds_rate cheking\n",
    "    bid_value_counts = dataset['ISBN'].value_counts()\n",
    "    item_interaction = bid_value_counts[bid_value_counts < 5].count()\n",
    "    print(f\"No. of items < 5 ineractions: {item_interaction}\")\n",
    "\n",
    "    items_counts = dataset['ISBN'].value_counts()\n",
    "    items_counts = items_counts.to_dict() #converts to dictionary\n",
    "    dataset['Count'] = dataset['ISBN'].map(items_counts)\n",
    "\n",
    "    dataset = filter_rows_by_values(dataset, \"Count\", list(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34797129",
   "metadata": {},
   "source": [
    "D. Print statistics after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41c44750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of users: 6358\n",
      "No. of Books: 6921\n",
      "No. of Interaction: 88552\n"
     ]
    }
   ],
   "source": [
    "# statistics on 5 rate explicit dataset (after pre-processing)\n",
    "print(f\"No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461efca",
   "metadata": {},
   "source": [
    "E. Save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "566c1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we save the preprocessed explicit dataset (5Rate) we first remove the added column which is `Count`\n",
    "del dataset['Count']\n",
    "dataset.to_csv(location_to_save+\"fairbook_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebdb7a",
   "metadata": {},
   "source": [
    "# 3. First look in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10f6b5",
   "metadata": {},
   "source": [
    "A. Read book file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0c80ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/items_books.csv\" # Books-Crossing books\n",
    "books = pd.read_csv(filename, low_memory = False).drop([\"Image-URL-S\", \"Image-URL-M\",\"Image-URL-L\"], axis=1) # read books and remove images\n",
    "books.columns = [\"ISBN\", \"title\", \"author\", \"year\", \"publisher\"] # rename columns to simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "346b99c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 271360 books.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(books))+\" books.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad138458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author  year                   publisher  \n",
       "0    Mark P. O. Morford  2002     Oxford University Press  \n",
       "1  Richard Bruce Wright  2001       HarperFlamingo Canada  \n",
       "2          Carlo D'Este  1991             HarperPerennial  \n",
       "3      Gina Bari Kolata  1999        Farrar Straus Giroux  \n",
       "4       E. J. W. Barber  1999  W. W. Norton &amp; Company  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2a111",
   "metadata": {},
   "source": [
    "B. Choose \"unique\" authors based on exact author name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdee6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.DataFrame(books.author.unique(), columns=[\"author\"]).dropna().reset_index().drop(\"index\", axis=1) # find unique authors and remove nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34bb433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 102023 unique authors.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(authors))+\" unique authors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a22bad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlo D'Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E. J. W. Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author\n",
       "0    Mark P. O. Morford\n",
       "1  Richard Bruce Wright\n",
       "2          Carlo D'Este\n",
       "3      Gina Bari Kolata\n",
       "4       E. J. W. Barber"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40377263",
   "metadata": {},
   "source": [
    "C. Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ce0d0",
   "metadata": {},
   "source": [
    "C.1 Non-latin named authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49960e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s): # function to check if a name is latin\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f3f2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[\"author_latin\"] = authors.author.apply(lambda x : isEnglish(x))\n",
    "num_latin_authors = len(authors[authors.author_latin == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e39f91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  100642 latin authors out of 102023.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \", num_latin_authors,\"latin authors out of\", str(len(authors))+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96e7fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "del authors[\"author_latin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908cf47",
   "metadata": {},
   "source": [
    "C.2 Author entries with a single name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5850e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[\"author_single\"] = authors.author.apply(lambda x: len(x.split(\" \"))==1)\n",
    "num_single_named_authors = len(authors[authors.author_single == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "219a0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2502 single named authors out of 102023.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \", num_single_named_authors,\"single named authors out of\", str(len(authors))+\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317d9b6",
   "metadata": {},
   "source": [
    "# 4. Access Google Books API\n",
    "Goal: To use the ISBNs from the dataset to get the author and title of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6228aae",
   "metadata": {},
   "source": [
    "A. Function to access the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89072856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_title(ISBN):\n",
    "    base_api_link = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "\n",
    "        \n",
    "    with urllib.request.urlopen(base_api_link + ISBN) as f:\n",
    "        text = f.read()\n",
    "    decoded_text = text.decode(\"utf-8\")\n",
    "    obj = json.loads(decoded_text) # deserializes decoded_text to a Python object\n",
    "    try:\n",
    "        volume_info = obj[\"items\"][0] \n",
    "    except: \n",
    "        \n",
    "        #print(obj)\n",
    "        return(\"\",\"\")\n",
    "    title = volume_info[\"volumeInfo\"][\"title\"]\n",
    "    try:\n",
    "        authors = volume_info[\"volumeInfo\"][\"authors\"]\n",
    "        \n",
    "    except:\n",
    "        #print(volume_info[\"volumeInfo\"])\n",
    "        return(\"\",title)\n",
    "\n",
    "    return(authors,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d0f6a",
   "metadata": {},
   "source": [
    "B. Initialize the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"alt_title\"] = \"\"\n",
    "books[\"alt_author\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145786e",
   "metadata": {},
   "source": [
    "C. Run the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fba026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for index,row in books.iloc[271000:].iterrows():\n",
    "    if row[\"alt_author\"]==\"\":\n",
    "        ISBN = row[\"ISBN\"]\n",
    "        print(row.title)\n",
    "        statement = True\n",
    "        i=0\n",
    "        while statement:\n",
    "\n",
    "            try:\n",
    "                authors, title = get_author_title(ISBN)\n",
    "                statement = False\n",
    "            except:\n",
    "                if i>50:\n",
    "                    statement = False\n",
    "                    print(\"IT FAILED MORE THAN 50 TIMES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                time.sleep(0.1)\n",
    "            i+=1  \n",
    "\n",
    "        if type(authors)==list:\n",
    "            authors = \"|\".join(authors)\n",
    "        books.at[index, \"alt_title\"] = title\n",
    "        books.at[index, \"alt_author\"] = authors\n",
    "    if index%100==0:\n",
    "        print(time.time()-start, index)\n",
    "        start = time.time()\n",
    "        time.sleep(5)\n",
    "        if index%1000==0:\n",
    "            print(\"SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            books.to_csv(location_to_save+\"items_books_some_isbn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea847b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(location_to_save+\"items_books_some_isbn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ba26a",
   "metadata": {},
   "source": [
    "# 5. Analyze results from Google Books API\n",
    "Goal: To check the structure and completeness of the Google Books information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086fabf",
   "metadata": {},
   "source": [
    "<b>A. Read file.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd2f04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(location_to_save + \"items_books_some_isbn.csv\", low_memory = False, index_col=0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc3f09",
   "metadata": {},
   "source": [
    "<b>B. Check completeness.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3246f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_results_authors = len(books[(books.alt_author==\"\")].drop_duplicates(subset = \"author\"))\n",
    "no_results_books = len(books[(books.alt_author==\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a6c7036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 6511 unique authors, we couldn't match the ISBN of at least one of their books, out of 102024 authors.\n",
      "For 10134 books, we couldn't match the ISBN, out of 271360 books.\n"
     ]
    }
   ],
   "source": [
    "print(\"For\", no_results_authors,\"unique authors, we couldn't match the ISBN of at least one of their books, out of\",len(books.drop_duplicates(subset = \"author\")), \"authors.\")\n",
    "print(\"For\", no_results_books,\"books, we couldn't match the ISBN, out of\", len(books), \"books.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77456da8",
   "metadata": {},
   "source": [
    "<b>C. Compare Book-Crossing with Google Books.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e45d2",
   "metadata": {},
   "source": [
    "<b>C.1 First estimation: Naive. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ad3f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first glance, we didn't find the same author for 92052 books out of  271360. However, it needs more processing.\n"
     ]
    }
   ],
   "source": [
    "first_estimation = len(books[books.author!=books.alt_author])\n",
    "print(\"At first glance, we didn't find the same author for\", first_estimation,\"books out of \",str(len(books))+\". However, it needs more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c6ec8",
   "metadata": {},
   "source": [
    "<b>C.2 Second estimation: Simplify author names.</b>\n",
    "\n",
    "We need a function that:\n",
    "1. Removes spaces\n",
    "2. Removes punctuation\n",
    "3. Makes lowercase\n",
    "\n",
    "<b>This way, we can more properly compare the strings.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf59e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(name):\n",
    "    name = name.replace(\" \",\"\").translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3b1c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvinagdaniil'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(\"Savvina G. Daniil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14d5ba",
   "metadata": {},
   "source": [
    "We create a column called \"correct_author\" where we replace it with the alt_author if simplified it is the same as the book crossing author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84ef3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"correct_author\"] = ''\n",
    "for index,row in books.iterrows():\n",
    "    if row.alt_author!=\"\":\n",
    "        if simplify(row.author)==simplify(row.alt_author):\n",
    "            books.at[index, \"correct_author\"] = row.alt_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c8e7b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the simplifying, we didn't find the same author for 81731 books out of  271360. However, it needs even more processing.\n"
     ]
    }
   ],
   "source": [
    "second_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With the simplifying, we didn't find the same author for\", second_estimation,\"books out of \",str(len(books))+\". However, it needs even more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5526b",
   "metadata": {},
   "source": [
    "#### C.3 Third estimation: Account for multiple authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848c384",
   "metadata": {},
   "source": [
    "Since in alt_author we collect all authors, we make sure that we consider if any of them (separated by \"|\") is the same as author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e7a443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in books.iterrows():\n",
    "    if row.correct_author==\"\": # only if we haven't already found the correct author of that book\n",
    "        if row.alt_author!=\"\": # if we got ISBN result\n",
    "            alt_author = row.alt_author\n",
    "            bag_of_alt_authors = alt_author.split(\"|\")\n",
    "            simplified_bag_of_alt_authors = [simplify(x) for x in bag_of_alt_authors]\n",
    "            author = simplify(row.author)\n",
    "            for i in range(len(bag_of_alt_authors)):\n",
    "                if author==simplified_bag_of_alt_authors[i]:\n",
    "                    books.at[index, \"correct_author\"] = bag_of_alt_authors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0a609b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With accounting for bag of authors, we didn't find the same author for 50833 books out of  271360. However, it needs even more processing.\n"
     ]
    }
   ],
   "source": [
    "third_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With accounting for bag of authors, we didn't find the same author for\", third_estimation,\"books out of \",str(len(books))+\". However, it needs even more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293c26b",
   "metadata": {},
   "source": [
    "#### C.4 Fourth estimation: Reverse names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e0ba1",
   "metadata": {},
   "source": [
    "I noticed that some names are reversed, e.g. Charles Glass and Glass Charles are not considered the same name by my processing. So I add an extra layer: sort the characters of the name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caee586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in books.iterrows():\n",
    "    if row.correct_author==\"\": # only if we haven't already found the correct author of that book\n",
    "        alt_author = row.alt_author\n",
    "        bag_of_alt_authors = alt_author.split(\"|\")\n",
    "        simplified_bag_of_alt_authors = [sorted(simplify(x)) for x in bag_of_alt_authors]\n",
    "        author = sorted(simplify(row.author))\n",
    "        for i in range(len(bag_of_alt_authors)):\n",
    "            if author==simplified_bag_of_alt_authors[i]:\n",
    "                books.at[index, \"correct_author\"] = bag_of_alt_authors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a4f5931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the sorting trick, we didn't find the same author for 49731 books out of  271360. However, it needs even more processing.\n"
     ]
    }
   ],
   "source": [
    "fourth_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With the sorting trick, we didn't find the same author for\", fourth_estimation,\"books out of \",str(len(books))+\". However, it needs even more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7f6e5",
   "metadata": {},
   "source": [
    "#### C.5 Fifth estimation: String similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30d13a",
   "metadata": {},
   "source": [
    "At this point, we can no longer rely on simply the literal comparison between strings. We need to introduce a similarity measure between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1ad1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a4b9f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9032258064516129, 0.2962962962962963)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"Savvina Daniil\", \"Savvina G. Daniil\"), similarity(\"Savvina Daniil\", \"John Williams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac758b49",
   "metadata": {},
   "source": [
    "I will consider every similarity over 0.7 to be the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9bf0998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in books.iterrows():\n",
    "    if row.correct_author==\"\": # only if we haven't already found the correct author of that book\n",
    "        alt_author = row.alt_author\n",
    "        bag_of_alt_authors = alt_author.split(\"|\")\n",
    "        simplified_bag_of_alt_authors = [sorted(simplify(x)) for x in bag_of_alt_authors]\n",
    "        author = sorted(simplify(row.author))\n",
    "        \n",
    "        max_sim = 0\n",
    "        max_i = -1000\n",
    "        \n",
    "        for i in range(len(bag_of_alt_authors)):\n",
    "            sim = similarity(author, simplified_bag_of_alt_authors[i])\n",
    "            if sim>max_sim:\n",
    "                max_sim = sim\n",
    "                max_i = i\n",
    "        \n",
    "        if max_sim>=0.7:\n",
    "            books.at[index, \"correct_author\"] = bag_of_alt_authors[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b9a0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the similarity threshold, we didn't find the same author for 22019 books out of  271360. At this point, it is hard to further progress.\n"
     ]
    }
   ],
   "source": [
    "fifth_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With the similarity threshold, we didn't find the same author for\", fifth_estimation,\"books out of \",str(len(books))+\". At this point, it is hard to further progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b791f1",
   "metadata": {},
   "source": [
    "#### C.6 Save first author from GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c28375",
   "metadata": {},
   "source": [
    "We may need to use them when running the viaf API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ceeca8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"alt_first_author\"] = books.alt_author.apply(lambda x: x.split(\"|\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c991b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>alt_title</th>\n",
       "      <th>alt_author</th>\n",
       "      <th>correct_author</th>\n",
       "      <th>alt_first_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford|Robert J. Lenardon</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Flu</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>The Mummies of Ürümchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author  year                   publisher  \\\n",
       "0    Mark P. O. Morford  2002     Oxford University Press   \n",
       "1  Richard Bruce Wright  2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este  1991             HarperPerennial   \n",
       "3      Gina Bari Kolata  1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber  1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                alt_title                             alt_author  \\\n",
       "0     Classical Mythology  Mark P. O. Morford|Robert J. Lenardon   \n",
       "1            Clara Callan                   Richard Bruce Wright   \n",
       "2    Decision in Normandy                           Carlo D'Este   \n",
       "3                     Flu                       Gina Bari Kolata   \n",
       "4  The Mummies of Ürümchi                        E. J. W. Barber   \n",
       "\n",
       "         correct_author      alt_first_author  \n",
       "0    Mark P. O. Morford    Mark P. O. Morford  \n",
       "1  Richard Bruce Wright  Richard Bruce Wright  \n",
       "2          Carlo D'Este          Carlo D'Este  \n",
       "3      Gina Bari Kolata      Gina Bari Kolata  \n",
       "4       E. J. W. Barber       E. J. W. Barber  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4597ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(location_to_save+\"items_books_some_isbn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd92510",
   "metadata": {},
   "source": [
    "# 6. Access VIAF API\n",
    "For the \"matching\" authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63d5efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(location_to_save+\"items_books_some_isbn.csv\", low_memory = False, index_col=0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25da0b5",
   "metadata": {},
   "source": [
    "A. Function to access the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94e0e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viaf_entry(author_name):\n",
    "    #print(author_name)\n",
    "    viaf = ViafAPI()\n",
    "    viaf_id = \"\"\n",
    "    viaf_name = \"\"\n",
    "    potential_entries = viaf.suggest(author_name)[:5]\n",
    "    if len(potential_entries)==0:\n",
    "        print(\"No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    for entry in potential_entries:\n",
    "        if entry[\"nametype\"]==\"personal\":\n",
    "            #print(entry[\"term\"])\n",
    "            try:\n",
    "                viaf_id = entry[\"viafid\"]\n",
    "                viaf_name = entry[\"term\"]\n",
    "                #print(\"We found viaf_id!\")\n",
    "            except:\n",
    "                print(author_name + \" has no Viaf ID.\")\n",
    "            break\n",
    "        print(\"ISSUE! We didn't find for\", author_name)\n",
    "    return viaf_id, viaf_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8913bfe",
   "metadata": {},
   "source": [
    "B. Initialize the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c7470e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"viaf_id\"] = \"\"\n",
    "books[\"viaf_name\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f287a",
   "metadata": {},
   "source": [
    "C. Define unique authors.\n",
    "\n",
    "The purpose is to not rerun the API again for the same \"correct author\" name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de0d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitive_unique_authors = books[books.correct_author!=\"\"].drop_duplicates(subset=\"correct_author\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b879e11",
   "metadata": {},
   "source": [
    "D. Run the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae2e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99018 0.0007455348968505859\n",
      "ISSUE! We didn't find for Syngress Media, Inc\n",
      "ISSUE! We didn't find for Syngress Media, Inc\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Berkley Publishing Group\n",
      "ISSUE! We didn't find for Berkley Publishing Group\n",
      "ISSUE! We didn't find for Berkley Publishing Group\n",
      "ISSUE! We didn't find for Berkley Publishing Group\n",
      "ISSUE! We didn't find for Berkley Publishing Group\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Berkley Publishing\n",
      "ISSUE! We didn't find for Berkley Publishing\n",
      "ISSUE! We didn't find for Berkley Publishing\n",
      "ISSUE! We didn't find for Berkley Publishing\n",
      "ISSUE! We didn't find for Berkley Publishing\n",
      "ISSUE! We didn't find for NSYNC\n",
      "ISSUE! We didn't find for NSYNC\n",
      "ISSUE! We didn't find for NSYNC\n",
      "ISSUE! We didn't find for NSYNC\n",
      "ISSUE! We didn't find for NSYNC\n",
      "try normal author name\n",
      "ISSUE! We didn't find for 'N Sync\n",
      "ISSUE! We didn't find for 'N Sync\n",
      "ISSUE! We didn't find for 'N Sync\n",
      "ISSUE! We didn't find for 'N Sync\n",
      "ISSUE! We didn't find for 'N Sync\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Merriam-Webster\n",
      "ISSUE! We didn't find for Merriam-Webster\n",
      "ISSUE! We didn't find for Merriam-Webster\n",
      "ISSUE! We didn't find for Merriam-Webster\n",
      "ISSUE! We didn't find for Merriam-Webster\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Pillsbury Company\n",
      "ISSUE! We didn't find for Pillsbury Company\n",
      "ISSUE! We didn't find for Pillsbury Company\n",
      "ISSUE! We didn't find for Pillsbury Company\n",
      "ISSUE! We didn't find for Pillsbury Company\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "ISSUE! We didn't find for Candlewick Press\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "try normal author name\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "ISSUE! We didn't find for American Yoga Association\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Falcon Press\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "ISSUE! We didn't find for Century Hutchinson\n",
      "100656 14.180898427963257\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Steck-Vaughn Company\n",
      "ISSUE! We didn't find for Steck-Vaughn Company\n",
      "ISSUE! We didn't find for Steck-Vaughn Company\n",
      "ISSUE! We didn't find for Steck-Vaughn Company\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for The Diagram Group\n",
      "try normal author name\n",
      "ISSUE! We didn't find for The Diagram Group\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Health Media of America\n",
      "ISSUE! We didn't find for Consumer Reports Books\n",
      "ISSUE! We didn't find for Consumer Reports Books\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Consumer Reports Books\n",
      "ISSUE! We didn't find for Consumer Reports Books\n",
      "ISSUE! We didn't find for Better Way Books\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "102396 252.91466522216797\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Independent Innkeepers Association\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Rabbi Ted Falcon\n",
      "ISSUE! We didn't find for Rabbi Ted Falcon\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "ISSUE! We didn't find for Monty Python\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Minnesota Humanities Commission\n",
      "ISSUE! We didn't find for Minnesota Humanities Commission\n",
      "ISSUE! We didn't find for Minnesota Humanities Commission\n",
      "ISSUE! We didn't find for Minnesota Humanities Commission\n",
      "ISSUE! We didn't find for Minnesota Humanities Commission\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Nextext\n",
      "ISSUE! We didn't find for Print Project\n",
      "ISSUE! We didn't find for Print Project\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Print Project\n",
      "ISSUE! We didn't find for Print Project\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Ladybird Books\n",
      "ISSUE! We didn't find for Ladybird Books\n",
      "ISSUE! We didn't find for Ladybird Books\n",
      "ISSUE! We didn't find for Ladybird Books\n",
      "ISSUE! We didn't find for Ladybird Books\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "ISSUE! We didn't find for Girl Scouts of the United States of America\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "104436 477.8022117614746\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for King Arthur Flour\n",
      "ISSUE! We didn't find for King Arthur Flour\n",
      "ISSUE! We didn't find for King Arthur Flour\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Saint Teresa (of Avila)\n",
      "ISSUE! We didn't find for Saint Teresa (of Avila)\n",
      "ISSUE! We didn't find for Saint Teresa (of Avila)\n",
      "ISSUE! We didn't find for Saint Teresa (of Avila)\n",
      "ISSUE! We didn't find for Saint Teresa (of Avila)\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "ISSUE! We didn't find for Group Publishing\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "106215 720.6065783500671\n",
      "ISSUE! We didn't find for Bad Dog Press\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Market House Books Ltd\n",
      "ISSUE! We didn't find for Market House Books Ltd\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Market House Books Ltd\n",
      "ISSUE! We didn't find for Market House Books Ltd\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Southern Living\n",
      "ISSUE! We didn't find for Southern Living\n",
      "ISSUE! We didn't find for Southern Living\n",
      "ISSUE! We didn't find for Southern Living\n",
      "ISSUE! We didn't find for Southern Living\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Christina Harland\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Christina Harland\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Word Publishing\n",
      "ISSUE! We didn't find for Word Publishing\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Word Publishing\n",
      "ISSUE! We didn't find for Word Publishing\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for George Philip & Son\n",
      "ISSUE! We didn't find for George Philip & Son\n",
      "ISSUE! We didn't find for George Philip & Son\n",
      "ISSUE! We didn't find for George Philip & Son\n",
      "ISSUE! We didn't find for George Philip & Son\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "ISSUE! We didn't find for Map Productions\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Great Britain. Home Office\n",
      "ISSUE! We didn't find for Great Britain. Home Office\n",
      "ISSUE! We didn't find for Great Britain. Home Office\n",
      "ISSUE! We didn't find for Great Britain. Home Office\n",
      "ISSUE! We didn't find for Great Britain. Home Office\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Great Britain\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for United States. Congress. Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States. Congress. Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States. Congress. Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States. Congress. Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States. Congress. Office of Technology Assessment\n",
      "try normal author name\n",
      "ISSUE! We didn't find for United States Congress Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States Congress Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States Congress Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States Congress Office of Technology Assessment\n",
      "ISSUE! We didn't find for United States Congress Office of Technology Assessment\n",
      "ISSUE! We didn't find for Us Government\n",
      "ISSUE! We didn't find for Us Government\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "try normal author name\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "ISSUE! We didn't find for British Medical Association\n",
      "107566 946.9837124347687\n",
      "ISSUE! We didn't find for Sunday Express\n",
      "ISSUE! We didn't find for Sunday Express\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Daily Express\n",
      "ISSUE! We didn't find for Daily Express\n",
      "ISSUE! We didn't find for Daily Express\n",
      "ISSUE! We didn't find for Daily Express\n",
      "ISSUE! We didn't find for Daily Express\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Detection Club\n",
      "ISSUE! We didn't find for Detection Club\n",
      "ISSUE! We didn't find for Detection Club\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Detection Club\n",
      "ISSUE! We didn't find for Detection Club\n",
      "ISSUE! We didn't find for Detection Club\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "ISSUE! We didn't find for Walker Books\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "ISSUE! We didn't find for Contemporary Books\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "try normal author name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "ISSUE! We didn't find for National Hockey League\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Fanya Gottesfeld Heller\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "try normal author name\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "ISSUE! We didn't find for U S Department of Agriculture\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "109050 1173.9242625236511\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for United States. Department of Agriculture\n",
      "ISSUE! We didn't find for United States. Department of Agriculture\n",
      "ISSUE! We didn't find for United States. Department of Agriculture\n",
      "ISSUE! We didn't find for United States. Department of Agriculture\n",
      "ISSUE! We didn't find for United States. Department of Agriculture\n",
      "try normal author name\n",
      "ISSUE! We didn't find for United States Dept. of Agriculture\n",
      "ISSUE! We didn't find for United States Dept. of Agriculture\n",
      "ISSUE! We didn't find for United States Dept. of Agriculture\n",
      "ISSUE! We didn't find for United States Dept. of Agriculture\n",
      "ISSUE! We didn't find for United States Dept. of Agriculture\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Prentice Hall\n",
      "ISSUE! We didn't find for Prentice Hall\n",
      "ISSUE! We didn't find for Prentice Hall\n",
      "ISSUE! We didn't find for Prentice Hall\n",
      "ISSUE! We didn't find for Prentice Hall\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "110444 1393.9623889923096\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Readers Digest\n",
      "ISSUE! We didn't find for Readers Digest\n",
      "ISSUE! We didn't find for Readers Digest\n",
      "ISSUE! We didn't find for Readers Digest\n",
      "ISSUE! We didn't find for Readers Digest\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Alcoholics Anonymous World Services\n",
      "ISSUE! We didn't find for Alcoholics Anonymous World Services\n",
      "ISSUE! We didn't find for Alcoholics Anonymous World Services\n",
      "ISSUE! We didn't find for Alcoholics Anonymous World Services\n",
      "ISSUE! We didn't find for Alcoholics Anonymous World Services\n",
      "try normal author name\n",
      "ISSUE! We didn't find for Alcoholics Anonymous\n",
      "ISSUE! We didn't find for Alcoholics Anonymous\n",
      "ISSUE! We didn't find for Alcoholics Anonymous\n",
      "ISSUE! We didn't find for Alcoholics Anonymous\n",
      "ISSUE! We didn't find for Alcoholics Anonymous\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for AAA Publishing\n",
      "ISSUE! We didn't find for AAA Publishing\n",
      "try normal author name\n",
      "ISSUE! We didn't find for AAA Publishing\n",
      "ISSUE! We didn't find for AAA Publishing\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ISSUE! We didn't find for Hyperion\n",
      "ISSUE! We didn't find for Hyperion\n",
      "ISSUE! We didn't find for Hyperion\n",
      "ISSUE! We didn't find for Hyperion\n",
      "ISSUE! We didn't find for Hyperion\n",
      "try normal author name\n",
      "ISSUE! We didn't find for HYPERION\n",
      "ISSUE! We didn't find for HYPERION\n",
      "ISSUE! We didn't find for HYPERION\n",
      "ISSUE! We didn't find for HYPERION\n",
      "ISSUE! We didn't find for HYPERION\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "try normal author name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "ISSUE! We didn't find for King James Bible\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n",
      "No results!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "try normal author name\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "i=0\n",
    "for index, row in definitive_unique_authors.iloc[36000:].iterrows():\n",
    "    if row.viaf_id==\"\":\n",
    "        author = row.correct_author\n",
    "        viaf_id, viaf_name = get_viaf_entry(author)\n",
    "        if viaf_id == \"\":\n",
    "            print(\"try normal author name\")\n",
    "            viaf_id, viaf_name = get_viaf_entry(row.author)\n",
    "        books.at[index, \"viaf_id\"] = viaf_id\n",
    "        books.at[index, \"viaf_name\"] = viaf_name\n",
    "        definitive_unique_authors.at[index, \"viaf_id\"] = viaf_id\n",
    "        definitive_unique_authors.at[index, \"viaf_name\"] = viaf_name\n",
    "    if i%500==0:\n",
    "        print(index, time.time()-start)\n",
    "        books.to_csv(location_to_save+\"items_books_after_viaf.csv\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"data/items_books_after_viaf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67614a12",
   "metadata": {},
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f846304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(location_to_save+\"items_books_after_viaf.csv\", dtype = object, index_col=0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c96a6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books[books.viaf_id!=\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44900829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
